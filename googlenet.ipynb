{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-04-22T13:41:25.328390300Z",
     "start_time": "2024-04-22T13:41:25.314827200Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "<torch._C.Generator at 0x16dff534b70>"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import torchvision\n",
    "from torchvision import datasets, models\n",
    "from torchvision.transforms import v2\n",
    "from torchvision.io import read_image\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "class AkuDataset(Dataset):\n",
    "    def __init__(self, X, y, transform=None):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sample = {\n",
    "            \"X\": self.X[idx],\n",
    "            \"y\": self.y[idx]\n",
    "        }\n",
    "\n",
    "        if self.transform:\n",
    "            sample[\"X\"] = self.transform(sample[\"X\"])\n",
    "\n",
    "        return sample\n",
    "\n",
    "def loadAkuDataset(labels_file, root_dir, data_split=(0.7, 0.2, 0.1), transform = None):\n",
    "    \"\"\"\n",
    "    @param labels_file: path to the csv file containing the labels for each image\n",
    "    @param root_dir: path to the dir containing the original and augmented image folders\n",
    "    @param data_split: three elements tuple containing the ratio of images for train, validation and test sets\n",
    "    @param transform: a concatenation of trasformations to apply to the images\n",
    "    @return a three element tuple containing the datasets for the training, validation and test sets\n",
    "    \"\"\"\n",
    "    X = []\n",
    "    y = []\n",
    "\n",
    "    # read the labels from the csv file\n",
    "    labels_df = pd.read_csv(labels_file)\n",
    "    labels_df.set_index(\"Unnamed: 0\", inplace=True)\n",
    "\n",
    "    # reading the original images\n",
    "    original_dir = f\"{root_dir}/original\"\n",
    "    for filename in os.listdir(original_dir):\n",
    "        path = f\"{original_dir}/{filename}\"\n",
    "        X.append( Image.open(path) )\n",
    "        y.append(labels_df.loc[filename].values)\n",
    "\n",
    "    # reading the augmented images\n",
    "    augmented_dir = f\"{root_dir}/augmented\"\n",
    "    for filename in os.listdir(augmented_dir):\n",
    "        path = f\"{augmented_dir}/{filename}\"\n",
    "        X.append( Image.open(path) )\n",
    "        y.append(labels_df.loc[filename].values)\n",
    "\n",
    "    # split the data in train, validation and test sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "    X_val, X_test, y_val, y_test = train_test_split(X_test, y_test, test_size = 0.1, random_state=42)\n",
    "\n",
    "    return AkuDataset(X_train, y_train, transform), AkuDataset(X_val, y_val, transform), AkuDataset(X_test, y_test, transform)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-22T13:41:25.343646500Z",
     "start_time": "2024-04-22T13:41:25.327141200Z"
    }
   },
   "id": "70f53c630fb2c2f6"
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "labels_file = \"./data/overall_labels.csv\"\n",
    "root_dir = \"./data\"\n",
    "BATCH_SIZE = 4\n",
    "\n",
    "# creating the datasets\n",
    "train_dataset, val_dataset, test_dataset = loadAkuDataset(\n",
    "    labels_file, \n",
    "    root_dir, \n",
    "    transform = v2.Compose([\n",
    "        v2.Resize(400),\n",
    "        v2.CenterCrop(256),\n",
    "        v2.ToDtype(torch.float32, scale=True),\n",
    "        v2.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ])\n",
    ")\n",
    "\n",
    "# creating the data loaders\n",
    "train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_dataloader = torch.utils.data.DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-22T13:41:25.649219400Z",
     "start_time": "2024-04-22T13:41:25.340025800Z"
    }
   },
   "id": "6ec3c1522b8c663e"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
