{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-02T09:57:54.399075Z",
     "start_time": "2024-05-02T09:57:54.383993400Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision.transforms import v2\n",
    "from torchvision.io import read_image, write_jpeg\n",
    "from torchvision.utils import save_image\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "if torch.cuda.is_available(): \n",
    " torch.set_default_device('cuda')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-02T09:57:54.418826800Z",
     "start_time": "2024-05-02T09:57:54.401072400Z"
    }
   },
   "id": "aaa96598629b081f"
  },
  {
   "cell_type": "markdown",
   "source": [
    "In this notebook we apply different transformations to our original samples in order to get a much higher number of possible samples for later classification."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "aa431e0deda7e1d0"
  },
  {
   "cell_type": "markdown",
   "id": "d3e1d51a14d093c3",
   "metadata": {},
   "source": [
    "# Gaussian Noise\n",
    "\n",
    "A function to apply Gaussian Noise to the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "543627a22b5017fa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-02T09:57:54.435602200Z",
     "start_time": "2024-05-02T09:57:54.421829Z"
    }
   },
   "outputs": [],
   "source": [
    "def gauss_noise_tensor(img):\n",
    "    assert isinstance(img, torch.Tensor)\n",
    "    dtype = img.dtype\n",
    "    if not img.is_floating_point():\n",
    "        img = img.to(torch.float32)\n",
    "    \n",
    "    sigma = 2\n",
    "    \n",
    "    out = img + sigma * torch.randn_like(img)\n",
    "    \n",
    "    if out.dtype != dtype:\n",
    "        out = out.to(dtype)\n",
    "        \n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "836fe7aeb12b7493",
   "metadata": {},
   "source": [
    "# Compose Transformation\n",
    "\n",
    "We perform data augmentation on our original images in order to get more images overall. The operations performed are, in order:\n",
    "- Random Cropping to a size of 400x400 (any higher would not be compatible with all images in the dataset)\n",
    "- Apply Gaussian Noise\n",
    "- An Horizontal Flip (50% probability)\n",
    "- An Vertical Flip with a (50% probability)\n",
    "- A random Erasing of parts of the image, from 2% up to 20% (50% probability)\n",
    "- A random shift of Perspective of the image (50% probability)\n",
    "- A random Affine transformation\n",
    "- A random Elastic transformation\n",
    "\n",
    "For each image we create 10 different augmented images, ending up with 11x our original sample size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "34d5666cf8b79bfd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-02T09:58:41.222732Z",
     "start_time": "2024-05-02T09:57:54.428602900Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ougi\\PycharmProjects\\CHL\\.venv\\Lib\\site-packages\\torch\\utils\\_device.py:78: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ..\\aten\\src\\ATen\\native\\cudnn\\Conv_v8.cpp:919.)\n",
      "  return func(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "data_folder = \"./data/original\"\n",
    "destination_folder = \"./data/augmented\"\n",
    "\n",
    "IMAGE_ITERATIONS = 10\n",
    "\n",
    "WIDTH_RATIO = 0.3\n",
    "HEIGHT_RATIO = 0.3\n",
    "\n",
    "labels_dict = {}\n",
    "\n",
    "for filename in os.listdir(f\"{data_folder}\"):\n",
    "    if filename == \".ipynb_checkpoints\":\n",
    "        continue\n",
    "    img = read_image(f\"{data_folder}/{filename}\")\n",
    "    filename_no_extension = filename.split(\".\")[0]\n",
    "    labels_dict[f\"{filename}\"] = {\n",
    "            \"HEALTHY\": 1 if \"HEALTHY\" in filename else 0,\n",
    "            \"AKU\": 1 if \"AKU\" in filename else 0\n",
    "        }\n",
    "    for x in range(IMAGE_ITERATIONS):\n",
    "        transform = v2.Compose([\n",
    "                                v2.RandomCrop(size=400),\n",
    "                                v2.Lambda(gauss_noise_tensor),\n",
    "                                v2.RandomHorizontalFlip(p=0.5),\n",
    "                                v2.RandomVerticalFlip(p=0.5),\n",
    "                                v2.RandomErasing(p=0.5, scale=(0.02, 0.2)),\n",
    "                                v2.RandomPerspective(p=0.5, distortion_scale=0.3),\n",
    "                                v2.RandomAffine(degrees=40, scale=[0.8, 1.2], translate=[0.2, 0.4], shear=5),\n",
    "                                v2.ElasticTransform(alpha=90.0, sigma=9.0)\n",
    "        ])                            \n",
    "        out = transform(img)\n",
    "        path = f'{destination_folder}/{filename_no_extension}_composed_{x}.jpg'\n",
    "        write_jpeg(out, path)\n",
    "\n",
    "        labels_dict[f\"{filename_no_extension}_composed_{x}.jpg\"] = {\n",
    "            \"HEALTHY\": 1 if \"HEALTHY\" in filename else 0,\n",
    "            \"AKU\": 1 if \"AKU\" in filename else 0\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edad65c031e485f6",
   "metadata": {},
   "source": [
    "# CutMix & MixUp\n",
    "\n",
    "Here we create a custom Dataset class to use with Pytorch's DataLoader object. This object loads up the original images in batches of 4 and computes both a CutMix or MixUp on them.\n",
    "- CutMix is an augmentation strategy that replaces part of an image with an identical sized part from another image\n",
    "- MixUp is an augmentation strategy that blends both images into a single one, with a different level of transparency each time\n",
    "\n",
    "We create a number of images equal to the number of images passed onto the DataLoader object. These augmented images' labels might be in the [0..1] range for both classes. The class with the higher value will be the one considered later on for classification purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7924955761ecdae7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-02T09:58:42.505168900Z",
     "start_time": "2024-05-02T09:58:41.223734800Z"
    }
   },
   "outputs": [],
   "source": [
    "NUM_CLASSES = 2\n",
    "\n",
    "class CustomImageDataset(Dataset):\n",
    "    def __init__(self, annotations_file, img_dir, transform=None, target_transform=None):\n",
    "        self.img_labels = pd.read_csv(annotations_file)\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = os.path.join(self.img_dir, self.img_labels.iloc[idx, 0])\n",
    "        image = read_image(img_path)\n",
    "        label = self.img_labels.iloc[idx, 1]\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        if self.target_transform:\n",
    "            label = self.target_transform(label)\n",
    "        return image, label\n",
    "    \n",
    "prepoc = v2.Compose([v2.PILToTensor(), v2.RandomCrop(size=400), v2.ToDtype(torch.float32, scale=True)])\n",
    "BATCH_SIZE = 4\n",
    "\n",
    "torch.set_default_device('cpu')\n",
    "    \n",
    "aku_dataset = CustomImageDataset('./labels.csv', f'{data_folder}', transform=prepoc)\n",
    "dataloader = DataLoader(aku_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "cutmix = v2.CutMix(num_classes=NUM_CLASSES)\n",
    "mixup = v2.MixUp(num_classes=NUM_CLASSES)\n",
    "#cutmix_or_mixup = v2.RandomChoice([cutmix, mixup])\n",
    "\n",
    "x = 0\n",
    "for images, labels in dataloader:\n",
    "    cutimages, cutlabels = cutmix(images, labels)\n",
    "    for i in range(cutimages.size(0)):\n",
    "        filename = f\"cutmix_{x+i}.jpg\"\n",
    "        save_image(cutimages[i, :, :, :], f'{destination_folder}/{filename}')    \n",
    "        labels_dict[filename] = {\n",
    "            \"HEALTHY\": cutlabels[i][0].item(),\n",
    "            \"AKU\": cutlabels[i][1].item()\n",
    "        }\n",
    "    miximages, mixlabels = mixup(images, labels)\n",
    "    for i in range(miximages.size(0)):\n",
    "        filename = f\"mixup_{x+i}.jpg\"\n",
    "        save_image(miximages[i, :, :, :], f'{destination_folder}/{filename}')\n",
    "        labels_dict[filename] = {\n",
    "            \"HEALTHY\": mixlabels[i][0].item(),\n",
    "            \"AKU\": mixlabels[i][1].item()\n",
    "        }\n",
    "    x+= BATCH_SIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f64c2a1d521aea1f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-02T09:58:42.518710400Z",
     "start_time": "2024-05-02T09:58:42.506236200Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame.from_dict(labels_dict, orient=\"index\")\n",
    "df.to_csv(\"./data/overall_labels.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
