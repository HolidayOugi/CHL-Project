{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4f0cfc03-8a2c-45e2-a332-2a8329331c95",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-08T08:03:48.612063900Z",
     "start_time": "2024-05-08T08:03:46.381818400Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "<torch._C.Generator at 0x2b237f2c170>"
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "import torch.nn.functional as F\n",
    "from torchvision.utils import make_grid, save_image\n",
    "\n",
    "from utils import visualize_cam, Normalize\n",
    "from gradcam import GradCAM, GradCAMpp\n",
    "\n",
    "import os\n",
    "\n",
    "from PIL import Image as Image\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "device = torch.device(\"cpu\")\n",
    "torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "In this notebook we calculate GradCAM for all samples. GradCAM is a visual XAI method to show which parts of the image are the most influential for classification. The PyTorch implementation used for this project is available [here](https://github.com/1Konny/gradcam_plus_plus-pytorch)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "98bbbfa86b913e82"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "# we load our previous resnet model\n",
    "model = torch.load('model.pt')\n",
    "model.eval()\n",
    "model = model.to(device)\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = True"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-08T08:03:48.735996Z",
     "start_time": "2024-05-08T08:03:48.613063100Z"
    }
   },
   "id": "426459c1eab79658"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "root_dir = \"./data\"\n",
    "\n",
    "Images = []\n",
    "\n",
    "# load all images\n",
    "\n",
    "original_dir = f\"{root_dir}/original\"\n",
    "for filename in os.listdir(original_dir):\n",
    "    path = f\"{original_dir}/{filename}\"\n",
    "    filename_no_extension = filename.split(\".\")[0]\n",
    "    Images.append(tuple([Image.open(path).convert('RGB'), filename_no_extension]))\n",
    "\n",
    "augmented_dir = f\"{root_dir}/augmented\"\n",
    "for filename in os.listdir(augmented_dir):\n",
    "    path = f\"{augmented_dir}/{filename}\"\n",
    "    filename_no_extension = filename.split(\".\")[0]\n",
    "    Images.append(tuple([Image.open(path).convert('RGB'), filename_no_extension]))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-08T08:03:49.913627800Z",
     "start_time": "2024-05-08T08:03:48.737945200Z"
    }
   },
   "id": "9876d8e68246d890"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ougi\\AppData\\Local\\Temp\\ipykernel_7800\\3920492370.py:3: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at ..\\torch\\csrc\\utils\\tensor_numpy.cpp:212.)\n",
      "  torch_img = torch.from_numpy(np.asarray(image)).permute(2, 0, 1).unsqueeze(0).float().div(255)\n",
      "C:\\Users\\Ougi\\PycharmProjects\\CHL\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1532: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return self._call_impl(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "for image, filename in Images:\n",
    "    # normalize and transform the image to tensor\n",
    "    normalizer = Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    torch_img = torch.from_numpy(np.asarray(image)).permute(2, 0, 1).unsqueeze(0).float().div(255)\n",
    "    torch_img = F.interpolate(torch_img, size=(256, 256), mode='bilinear', align_corners=False)\n",
    "    normed_torch_img = normalizer(torch_img)\n",
    "    \n",
    "    # load gradcam\n",
    "    cam_dict = dict()\n",
    "    resnet_model_dict = dict(type='resnet', arch=model, layer_name='layer4', input_size=(256, 256))\n",
    "    resnet_gradcam = GradCAM(resnet_model_dict, True)\n",
    "    resnet_gradcampp = GradCAMpp(resnet_model_dict, True)\n",
    "    cam_dict['resnet'] = [resnet_gradcam, resnet_gradcampp]\n",
    "    outputs = []\n",
    "    for gradcam, gradcam_pp in cam_dict.values():\n",
    "        # calculate gradcam mask for all images\n",
    "        mask, _ = gradcam(normed_torch_img)\n",
    "        heatmap, result = visualize_cam(mask, torch_img)\n",
    "    \n",
    "        mask_pp, _ = gradcam_pp(normed_torch_img)\n",
    "        heatmap_pp, result_pp = visualize_cam(mask_pp, torch_img)\n",
    "        \n",
    "        outputs.append(torch.stack([torch_img.squeeze().cpu(), heatmap, heatmap_pp, result, result_pp], 0))\n",
    "    \n",
    "    \n",
    "    outputs = make_grid(torch.cat(outputs, 0), nrow=5)\n",
    "    output_dir = './data/gradcam'\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    output_name = f\"{filename}_gradcam.jpg\"\n",
    "    output_path = os.path.join(output_dir, output_name)\n",
    "    \n",
    "    save_image(outputs, output_path)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-08T08:06:08.661603900Z",
     "start_time": "2024-05-08T08:03:49.916750700Z"
    }
   },
   "id": "542a3d2c0684e465"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
